{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations \n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import palettable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_ind(task, a_pokes, b_pokes): \n",
    "    \"\"\" Create Task IDs for that are consistent: in Task 1 A and B at left right extremes, in Task 2 B is one of the diagonal ones, \n",
    "    in Task 3  B is top or bottom \"\"\"\n",
    "    taskid = np.zeros(len(task));\n",
    "    taskid[b_pokes == 10 - a_pokes] = 1     \n",
    "    taskid[np.logical_or(np.logical_or(b_pokes == 2, b_pokes == 3), np.logical_or(b_pokes == 7, b_pokes == 8))] = 2  \n",
    "    taskid[np.logical_or(b_pokes ==  1, b_pokes == 9)] = 3  \n",
    "    \n",
    "    return taskid\n",
    "\n",
    "your_path = '/Users/veronikasamborska/Desktop/' # change path to where github folder is stored on your machine\n",
    "# load data (for the main figures we used data after removing variance associated with physical movement)\n",
    "def import_data(your_path):\n",
    "    HP = io.loadmat(your_path +'notebooks_paper/cells/data_recordings/HP.mat')\n",
    "    PFC = io.loadmat(your_path + 'notebooks_paper/cells/data_recordings/PFC.mat')\n",
    "    return HP, PFC\n",
    "\n",
    "HP, PFC =  import_data(your_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_trial_states(data, task_test = 0, H = 0, perm = True, decoder_full = True):\n",
    "    '''Simple linear decoding of position in the trial (Initiation, A/B choice/reward/no-reward) \n",
    "    using data from one problem, and tested the decoding performance on a different problem (Figure 3F, G).'''\n",
    "    \n",
    "    HP_1 = 15; HP_2 = 7 # sessions to split by animals \n",
    "    PFC_1 = 9; PFC_2 = 16; PFC_3 = 13\n",
    "    \n",
    "    cnf_matrix_subj_x_y = [] # task x to y confusion matrix\n",
    "    cnf_matrix_subj_y_x = [] # task y to x confusion matrix\n",
    "   \n",
    "    if H == 0 and perm == False: # split HP data for each animal\n",
    "        HP_all_sessions_1 = data['DM'][0][:HP_1]; HP_all_sessions_2 = data['DM'][0][HP_1:HP_1+HP_2]\n",
    "        HP_all_sessions_3 = data['DM'][0][HP_1+HP_2:]\n",
    "       \n",
    "        HP_all_sessions_1_fr = data['Data'][0][:HP_1]; HP_all_sessions_2_fr = data['Data'][0][HP_1:HP_1+HP_2]\n",
    "        HP_all_sessions_3_fr = data['Data'][0][HP_1+HP_2:]\n",
    "        \n",
    "        all_subjects_dm = [HP_all_sessions_1,HP_all_sessions_2, HP_all_sessions_3]\n",
    "        all_subjects_data = [HP_all_sessions_1_fr,HP_all_sessions_2_fr, HP_all_sessions_3_fr]\n",
    "        \n",
    "    elif H != 0 and perm == False: # split PFC data for each animal\n",
    "        PFC_all_sessions_1 = data['DM'][0][:PFC_1]; PFC_all_sessions_2 = data['DM'][0][PFC_1:PFC_1+PFC_2]\n",
    "        PFC_all_sessions_3 = data['DM'][0][PFC_1+PFC_2:PFC_1+PFC_2+PFC_3];  PFC_all_sessions_4 = data['DM'][0][PFC_1+PFC_2+PFC_3:]\n",
    "        \n",
    "        PFC_all_sessions_1_fr = data['Data'][0][:PFC_1]; PFC_all_sessions_2_fr = data['Data'][0][PFC_1:PFC_1+PFC_2]\n",
    "        PFC_all_sessions_3_fr = data['Data'][0][PFC_1+PFC_2:PFC_1+PFC_2+PFC_3]; PFC_all_sessions_4_fr = data['Data'][0][PFC_1+PFC_2+PFC_3:]\n",
    "        \n",
    "        all_subjects_dm = [PFC_all_sessions_1,PFC_all_sessions_2, PFC_all_sessions_3,PFC_all_sessions_4]\n",
    "        all_subjects_data = [PFC_all_sessions_1_fr,PFC_all_sessions_2_fr, PFC_all_sessions_3_fr,PFC_all_sessions_4_fr]\n",
    "        \n",
    "    elif perm == True: # data selection if it's a permutation test\n",
    "        all_subjects_dm = data[0];  all_subjects_data = data[1]\n",
    "    \n",
    "    for ss,subj in enumerate(all_subjects_dm): # loop through subjects\n",
    "        y = all_subjects_dm[ss]; X = all_subjects_data[ss]\n",
    "        all_sessions_a1 = []; all_sessions_a2 = []; all_sessions_b1 = [];  all_sessions_b2 = [] \n",
    "    \n",
    "        for s, sess in enumerate(X): # loop through sessions\n",
    "            firing_rates_all_time = X[s]; DM = y[s]     \n",
    "            choices = DM[:,1]; choices_a = np.where(choices  == 1)[0]; choices_b = np.where(choices  == 0)[0]\n",
    "            reward = DM[:,2]; reward_p = np.where(reward == 1)[0];  reward_n = np.where(reward == 0)[0]\n",
    "            task  = DM[:,5]; poke_A = DM[:,6];  poke_B = DM[:,7]     \n",
    "            taskid = task_ind(task,poke_A,poke_B); task_1 = np.where(taskid  == 1)[0]; task_2 = np.where(taskid  == 2)[0]; task_3 = np.where(taskid  == 3)[0]\n",
    "            \n",
    "            min_trials_in_task = 10 # only take sessions with enough trials for training and testing\n",
    "            initiation = 24; ind_choice = 35; ind_reward = 42; bins_around = 1 # indicies where init, ch, reward and bins around\n",
    "            ind_around_init = np.arange(initiation-bins_around, initiation+bins_around)\n",
    "            ind_around_choice = np.arange(ind_choice-bins_around, ind_choice+bins_around)\n",
    "            ind_around_reward =  np.arange(ind_reward, ind_reward+(2*bins_around))\n",
    "    \n",
    "            if task_test == 1: # task 1 & 2\n",
    "                task_n1 = task_1; task_n2 = task_2\n",
    "            elif task_test == 2: # task 1 & 3\n",
    "                task_n1 = task_1; task_n2 = task_3\n",
    "            elif task_test == 3: # task 2 & 3\n",
    "                task_n1 = task_2;  task_n2 = task_3\n",
    "            \n",
    "            # choices A & B in the two tasks\n",
    "            choices_a_1 = np.intersect1d(choices_a, task_n1);  choices_b_1 = np.intersect1d(choices_b, task_n1)\n",
    "            choices_a_2 = np.intersect1d(choices_a, task_n2); choices_b_2 = np.intersect1d(choices_b, task_n2)\n",
    "            \n",
    "            # rewards and no-rewards on A & B in two takss \n",
    "            choices_a_1_r = np.intersect1d(choices_a_1, reward_p);choices_a_2_r = np.intersect1d(choices_a_2, reward_p)\n",
    "            choices_b_1_r = np.intersect1d(choices_b_1, reward_p);  choices_b_2_r = np.intersect1d(choices_b_2, reward_p) \n",
    "            \n",
    "            choices_a_1_nr = np.intersect1d(choices_a_1, reward_n); choices_a_2_nr = np.intersect1d(choices_a_2, reward_n)\n",
    "            choices_b_1_nr = np.intersect1d(choices_b_1, reward_n); choices_b_2_nr = np.intersect1d(choices_b_2, reward_n)\n",
    "            \n",
    "            \n",
    "            if len(choices_a_1_r) > min_trials_in_task and  len(choices_a_2_r) > min_trials_in_task \\\n",
    "                and  len(choices_b_1_r) > min_trials_in_task and  len(choices_b_2_r) > min_trials_in_task \\\n",
    "                and len(choices_a_1_nr) > min_trials_in_task and  len(choices_a_2_nr) > min_trials_in_task \\\n",
    "                and len(choices_b_1_nr) > min_trials_in_task and  len(choices_b_2_nr) > min_trials_in_task :    \n",
    "                index = int((min_trials_in_task)/2)+1\n",
    "\n",
    "                # initiations\n",
    "                fr_1_init = firing_rates_all_time[task_n1]; fr_1_init =  fr_1_init[:,:,ind_around_init][-index:];  fr_1_init = np.concatenate(np.transpose(fr_1_init,[0,2,1]),0)\n",
    "                fr_2_init = firing_rates_all_time[task_n2]; fr_2_init =  fr_2_init[:,:,ind_around_init][-index:]; fr_2_init = np.concatenate(np.transpose(fr_2_init,[0,2,1]),0)\n",
    "                \n",
    "                # A choices task 1 \n",
    "                fr_a_1_ch = firing_rates_all_time[choices_a_1]; fr_a_1_ch =  fr_a_1_ch[:,:,ind_around_choice][-index:]; fr_a_1_ch = np.concatenate(np.transpose(fr_a_1_ch,[0,2,1]),0)\n",
    "                fr_a_1_ch_r = firing_rates_all_time[choices_a_1_r]; fr_a_1_ch_r =  fr_a_1_ch_r[:,:,ind_around_reward][-index:]; fr_a_1_ch_r = np.concatenate(np.transpose(fr_a_1_ch_r,[0,2,1]),0)\n",
    "                fr_a_1_ch_nr = firing_rates_all_time[choices_a_1_nr]; fr_a_1_ch_nr =  fr_a_1_ch_nr[:,:,ind_around_reward][-index:]; fr_a_1_ch_nr = np.concatenate(np.transpose(fr_a_1_ch_nr,[0,2,1]),0)\n",
    "                \n",
    "                # A choices task 2\n",
    "                fr_a_2_ch = firing_rates_all_time[choices_a_2]; fr_a_2_ch = fr_a_2_ch[:,:,ind_around_choice][-index:]; fr_a_2_ch = np.concatenate(np.transpose(fr_a_2_ch,[0,2,1]),0)\n",
    "                fr_a_2_ch_r = firing_rates_all_time[choices_a_2_r]; fr_a_2_ch_r =  fr_a_2_ch_r[:,:,ind_around_reward][-index:]; fr_a_2_ch_r = np.concatenate(np.transpose(fr_a_2_ch_r,[0,2,1]),0)\n",
    "                fr_a_2_ch_nr = firing_rates_all_time[choices_a_2_nr]; fr_a_2_ch_nr =  fr_a_2_ch_nr[:,:,ind_around_reward][-index:]; fr_a_2_ch_nr = np.concatenate(np.transpose(fr_a_2_ch_nr,[0,2,1]),0)\n",
    "                \n",
    "                # B choices task 1 \n",
    "                fr_b_1_ch = firing_rates_all_time[choices_b_1]; fr_b_1_ch =  fr_b_1_ch[:,:,ind_around_choice][-index:]; fr_b_1_ch = np.concatenate(np.transpose(fr_b_1_ch,[0,2,1]),0)\n",
    "                fr_b_1_ch_r = firing_rates_all_time[choices_b_1_r]; fr_b_1_ch_r =  fr_b_1_ch_r[:,:,ind_around_reward][-index:]; fr_b_1_ch_r = np.concatenate(np.transpose(fr_b_1_ch_r,[0,2,1]),0)\n",
    "                fr_b_1_ch_nr = firing_rates_all_time[choices_b_1_nr]; fr_b_1_ch_nr =  fr_b_1_ch_nr[:,:,ind_around_reward][-index:]; fr_b_1_ch_nr = np.concatenate(np.transpose(fr_b_1_ch_nr,[0,2,1]),0)\n",
    "        \n",
    "                # B choices task 2\n",
    "                fr_b_2_ch = firing_rates_all_time[choices_b_2]; fr_b_2_ch = fr_b_2_ch[:,:,ind_around_choice][-index:]; fr_b_2_ch = np.concatenate(np.transpose(fr_b_2_ch,[0,2,1]),0)\n",
    "                fr_b_2_ch_r = firing_rates_all_time[choices_b_2_r]; fr_b_2_ch_r =  fr_b_2_ch_r[:,:,ind_around_reward][-index:];  fr_b_2_ch_r = np.concatenate(np.transpose(fr_b_2_ch_r,[0,2,1]),0)\n",
    "                fr_b_2_ch_nr = firing_rates_all_time[choices_b_2_nr]; fr_b_2_ch_nr = fr_b_2_ch_nr[:,:,ind_around_reward][-index:]; fr_b_2_ch_nr = np.concatenate(np.transpose(fr_b_2_ch_nr,[0,2,1]),0)\n",
    "        \n",
    "                all_sessions_a1.append(np.vstack([fr_1_init,fr_a_1_ch,fr_a_1_ch_r,fr_a_1_ch_nr]))\n",
    "                all_sessions_a2.append(np.vstack([fr_2_init,fr_a_2_ch,fr_a_2_ch_r,fr_a_2_ch_nr]))\n",
    "                all_sessions_b1.append(np.vstack([fr_b_1_ch,fr_b_1_ch_r,fr_b_1_ch_nr]))\n",
    "                all_sessions_b2.append(np.vstack([fr_b_2_ch,fr_b_2_ch_r,fr_b_2_ch_nr]))\n",
    "        \n",
    "        # create firing rates matrices for each subject (combine sessions together)\n",
    "        all_sessions_b1 = np.concatenate(all_sessions_b1,1); all_sessions_b2 = np.concatenate(all_sessions_b2,1)\n",
    "        all_sessions_a1 = np.concatenate(all_sessions_a1,1); all_sessions_a2 = np.concatenate(all_sessions_a2,1)\n",
    "       \n",
    "        training_1 = np.vstack([all_sessions_a1,all_sessions_b1]); training_2 = np.vstack([all_sessions_a2,all_sessions_b2])\n",
    "        bins = np.hstack([np.zeros(index*len(ind_around_init)), np.zeros(index*len(ind_around_init))+1, np.zeros(index*len(ind_around_init))+2, np.zeros(index*len(ind_around_init))+3,\n",
    "                              np.zeros(index*len(ind_around_init))+4, np.zeros(index*len(ind_around_init))+5, np.zeros(index*len(ind_around_init))+6])\n",
    "                \n",
    "        # across tasks\n",
    "        # task x to y decoding\n",
    "        model_nb = svm.SVC(gamma='scale')\n",
    "        model_nb.fit(training_1,bins)  \n",
    "        y_pred_class = model_nb.predict(training_2)\n",
    "            \n",
    "        cnf_matrix = metrics.confusion_matrix(bins,y_pred_class)\n",
    "        cnf_matrix = (cnf_matrix/np.sum(cnf_matrix,1))*100 \n",
    "            \n",
    "        # task y to x decoding\n",
    "        model_nb = svm.SVC(gamma='scale')\n",
    "        model_nb.fit(training_2,bins)  \n",
    "        y_pred_class_2 = model_nb.predict(training_1)\n",
    "          \n",
    "        cnf_matrix_2 = metrics.confusion_matrix(bins,y_pred_class_2)\n",
    "        cnf_matrix_2 = (cnf_matrix_2/np.sum(cnf_matrix_2,1))*100 \n",
    "  \n",
    "        cnf_matrix_subj_x_y.append(cnf_matrix) # list of all subjects' confusion matrices x y\n",
    "        cnf_matrix_subj_y_x.append(cnf_matrix_2) # list of all subjects' confusion matrices y x\n",
    "\n",
    "            \n",
    "    return cnf_matrix_subj_x_y, cnf_matrix_subj_y_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_subjects(HP, PFC):\n",
    "    '''' Function to permute subjects and run decoder in all task combinations (Figure 3F, G).'''\n",
    "    \n",
    "    HP_1 = 15; HP_2 = 7 # # sessions to split by animals \n",
    "    PFC_1 = 9; PFC_2 = 16; PFC_3 = 13 \n",
    "    \n",
    "    # organise data for pemuting subjects between groups\n",
    "    HP_all_sessions_1 = HP['DM'][0][:HP_1]; HP_all_sessions_2 = HP['DM'][0][HP_1:HP_1+HP_2]; HP_all_sessions_3 = HP['DM'][0][HP_1+HP_2:]\n",
    "    \n",
    "    PFC_all_sessions_1 = PFC['DM'][0][:PFC_1]; PFC_all_sessions_2 = PFC['DM'][0][PFC_1:PFC_1+PFC_2]\n",
    "    PFC_all_sessions_3 = PFC['DM'][0][PFC_1+PFC_2:PFC_1+PFC_2+PFC_3]; PFC_all_sessions_4 = PFC['DM'][0][PFC_1+PFC_2+PFC_3:]\n",
    "    \n",
    "    HP_all_sessions_1_fr = HP['Data'][0][:HP_1]; HP_all_sessions_2_fr = HP['Data'][0][HP_1:HP_1+HP_2]\n",
    "    HP_all_sessions_3_fr = HP['Data'][0][HP_1+HP_2:]\n",
    "\n",
    "    PFC_all_sessions_1_fr = PFC['Data'][0][:PFC_1]; PFC_all_sessions_2_fr = PFC['Data'][0][PFC_1:PFC_1+PFC_2]\n",
    "    PFC_all_sessions_3_fr = PFC['Data'][0][PFC_1+PFC_2:PFC_1+PFC_2+PFC_3]; PFC_all_sessions_4_fr = PFC['Data'][0][PFC_1+PFC_2+PFC_3:]\n",
    "   \n",
    "    all_subjects = [HP_all_sessions_1,HP_all_sessions_2, HP_all_sessions_3,PFC_all_sessions_1,PFC_all_sessions_2, PFC_all_sessions_3,PFC_all_sessions_4]\n",
    "    all_subjects_firing = [HP_all_sessions_1_fr,HP_all_sessions_2_fr, HP_all_sessions_3_fr,PFC_all_sessions_1_fr,PFC_all_sessions_2_fr, PFC_all_sessions_3_fr,PFC_all_sessions_4_fr]\n",
    "\n",
    "    animals_PFC = [0,1,2,3]; animals_HP = [4,5,6]\n",
    "    m, n = len(animals_PFC), len(animals_HP)\n",
    "    # arrays to store permutations for x to y task decoding\n",
    "    perm_pfc_1_2_xy = []; perm_pfc_1_3_xy = [];  perm_pfc_2_3_xy = []\n",
    "    perm_hp_1_2_xy = []; perm_hp_1_3_xy = [];  perm_hp_2_3_xy = []\n",
    "    \n",
    "    # arrays to store permutations for y to x task decoding\n",
    "    perm_pfc_1_2_yx = []; perm_pfc_1_3_yx = [];  perm_pfc_2_3_yx = []\n",
    "    perm_hp_1_2_yx = []; perm_hp_1_3_yx = [];  perm_hp_2_3_yx = []\n",
    "    for indices_PFC in combinations(range(m + n), m):\n",
    "        indices_HP = [i for i in range(m + n) if i not in indices_PFC]\n",
    "       \n",
    "        PFC_shuffle_dm = np.asarray(all_subjects)[np.asarray(indices_PFC)];  HP_shuffle_dm = np.asarray(all_subjects)[np.asarray(indices_HP)]\n",
    "        PFC_shuffle_f = np.asarray(all_subjects_firing)[np.asarray(indices_PFC)]; HP_shuffle_f = np.asarray(all_subjects_firing)[np.asarray(indices_HP)]\n",
    "        HP_shuffle= [HP_shuffle_dm,HP_shuffle_f]; PFC_shuffle = [PFC_shuffle_dm,PFC_shuffle_f]\n",
    "        \n",
    "        cnf_matrix_subj_pfc_perm_1_2, cnf_matrix_subj_pfc_perm_1_2_2 = decoder_trial_states(PFC_shuffle, task_test = 1, H = 1, perm = True)\n",
    "        cnf_matrix_subj_pfc_perm_1_3, cnf_matrix_subj_pfc_perm_1_3_2 = decoder_trial_states(PFC_shuffle, task_test = 2, H = 1, perm = True)\n",
    "        cnf_matrix_subj_pfc_perm_2_3, cnf_matrix_subj_pfc_perm_2_3_2 = decoder_trial_states(PFC_shuffle, task_test = 3, H = 1, perm = True)\n",
    "\n",
    "        cnf_matrix_subj_hp_perm_1_2, cnf_matrix_subj_hp_perm_1_2_2 = decoder_trial_states(HP_shuffle, task_test = 1, H = 1, perm = True)\n",
    "        cnf_matrix_subj_hp_perm_1_3, cnf_matrix_subj_hp_perm_1_3_2 = decoder_trial_states(HP_shuffle, task_test = 2, H = 1, perm = True)\n",
    "        cnf_matrix_subj_hp_perm_2_3, cnf_matrix_subj_hp_perm_2_3_2 = decoder_trial_states(HP_shuffle, task_test = 3, H = 1, perm = True)\n",
    "        \n",
    "        # permutation confusion matrices for x to y task decoding\n",
    "        perm_pfc_1_2_xy.append(np.mean(cnf_matrix_subj_pfc_perm_1_2,0))\n",
    "        perm_pfc_1_3_xy.append(np.mean(cnf_matrix_subj_pfc_perm_1_3,0))\n",
    "        perm_pfc_2_3_xy.append(np.mean(cnf_matrix_subj_pfc_perm_2_3,0))\n",
    "\n",
    "        perm_hp_1_2_xy.append(np.mean(cnf_matrix_subj_hp_perm_1_2,0))\n",
    "        perm_hp_1_3_xy.append(np.mean(cnf_matrix_subj_hp_perm_1_3,0))\n",
    "        perm_hp_2_3_xy.append(np.mean(cnf_matrix_subj_hp_perm_2_3,0))\n",
    "\n",
    "        # permutation confusion matrices for x to y task decoding\n",
    "        perm_pfc_1_2_yx.append(np.mean(cnf_matrix_subj_pfc_perm_1_2_2,0))\n",
    "        perm_pfc_1_3_yx.append(np.mean(cnf_matrix_subj_pfc_perm_1_3_2,0))\n",
    "        perm_pfc_2_3_yx.append(np.mean(cnf_matrix_subj_pfc_perm_2_3_2,0))\n",
    "            \n",
    "        perm_hp_1_2_yx.append(np.mean(cnf_matrix_subj_hp_perm_1_2_2,0))\n",
    "        perm_hp_1_3_yx.append(np.mean(cnf_matrix_subj_hp_perm_1_3_2,0))\n",
    "        perm_hp_2_3_yx.append(np.mean(cnf_matrix_subj_hp_perm_2_3_2,0))\n",
    "           \n",
    "    \n",
    "    perm_all_xy = [perm_pfc_1_2_xy, perm_pfc_1_3_xy, perm_pfc_2_3_xy, perm_hp_1_2_xy, perm_hp_1_3_xy, perm_hp_2_3_xy]\n",
    "    perm_all_yx = [perm_pfc_1_2_yx, perm_pfc_1_3_yx, perm_pfc_2_3_yx, perm_hp_1_2_yx, perm_hp_1_3_yx, perm_hp_2_3_yx]\n",
    "\n",
    "    subj_hp_xy = [];  subj_hp_yx = []\n",
    "    for cond in np.arange(3)+1:\n",
    "        cnf_matrix_subj_x_y, cnf_matrix_subj_y_x = decoder_trial_states(HP, task_test = cond, H = 0, perm = False)\n",
    "        subj_hp_xy.append(cnf_matrix_subj_x_y)\n",
    "        subj_hp_yx.append(cnf_matrix_subj_y_x)\n",
    "\n",
    "    subj_pfc_xy = [];  subj_pfc_yx = []\n",
    "    for cond in np.arange(3)+1:\n",
    "        cnf_matrix_subj_x_y, cnf_matrix_subj_y_x  = decoder_trial_states(PFC,task_test = cond, H = 1, perm = False)\n",
    "        subj_pfc_xy.append(cnf_matrix_subj_x_y)\n",
    "        subj_pfc_yx.append(cnf_matrix_subj_y_x)\n",
    "  \n",
    "            \n",
    "    return  perm_all_xy, perm_all_yx, subj_hp_xy, subj_hp_yx, subj_pfc_yx, subj_pfc_yx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(HP, PFC):  \n",
    "    '''' Plotting function for different patterns of decoding in Figure 3F, G.'''\n",
    "\n",
    "    perm_all, perm_all_2, matrix_hp_1, matrix_hp_2, matrix_pfc_1, matrix_pfc_2 =  permute_subjects(HP, PFC) \n",
    "    cmap =  palettable.scientific.sequential.Acton_3.mpl_colormap\n",
    "    \n",
    "    # plot average decoding matrices between all task pairs\n",
    "    av_pfc_tasks = np.mean(np.mean(np.mean([matrix_pfc_1,matrix_pfc_2],0),0),0)\n",
    "    av_hp_tasks = np.mean(np.mean(np.mean([matrix_hp_1,matrix_hp_2],0),0),0)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10, 5)); \n",
    "    titles = ['HP', 'PFC']\n",
    "    for c, conf in enumerate([av_hp_tasks, av_pfc_tasks]):\n",
    "        img = axs[c].imshow(conf,cmap = cmap, vmin = 0, vmax = 100)\n",
    "        axs[c].set_xticks(range(7))\n",
    "        axs[c].set_xticklabels(['Initiation','A choice', 'A reward', 'A no-reward',\\\n",
    "                                  'B choice', 'B reward', 'B no-reward'], rotation = 'vertical')\n",
    "        if c == 0:\n",
    "            axs[c].set_yticks(range(7))\n",
    "            axs[c].set_yticklabels(['Initiation','A choice', 'A reward', 'A no-reward',\\\n",
    "                                      'B choice', 'B reward', 'B no-reward'])\n",
    "        axs[c].set_title(titles[c])\n",
    "\n",
    "    fig.colorbar(img, ax = axs)\n",
    "    fig.colorbar(label ='Decoding (%)')\n",
    "\n",
    "    ## REAL DIFFERENCES\n",
    "    \n",
    "    ### Init B task (task 2 --> 3; 3 --> 2)\n",
    "    # Init and B PFC\n",
    "    subj_pfc_t2_3_b = np.asarray(matrix_pfc_1)[2,:,0,4]; subj_pfc_t3_2_b = np.asarray(matrix_pfc_2)[2,:,4,0]\n",
    "    subj_pfc_b = np.mean([subj_pfc_t2_3_b,subj_pfc_t3_2_b],0); std_pfc_b  = np.std(subj_pfc_b)/np.sqrt(len(subj_pfc_b))\n",
    "\n",
    "    # Init and B HP\n",
    "    subj_hp_t2_3_b = np.asarray(matrix_hp_1)[2,:,0,4];  subj_hp_t3_2_b = np.asarray(matrix_hp_2)[2,:,4,0]\n",
    "    subj_hp_b = np.mean([subj_hp_t2_3_b,subj_hp_t3_2_b],0); std_hp_b  = np.std(subj_hp_b)/np.sqrt(len(subj_hp_b))\n",
    "    IB_real =  np.mean(subj_hp_b) - np.mean(subj_pfc_b)\n",
    "\n",
    "    # average across tasks for the rest of the analyses\n",
    "    subj_hp_all = np.mean([matrix_hp_1, matrix_hp_2],0); subj_pfc_all = np.mean([matrix_pfc_1, matrix_pfc_2],0)\n",
    "   \n",
    "    # Generalisation HP\n",
    "    subj_hp_gen = np.mean(subj_hp_all,0)\n",
    "    subj_hp_gen = [np.mean(np.diag(subj_hp_gen[0])[4:]), np.mean(np.diag(subj_hp_gen[1])[4:]),np.mean(np.diag(subj_hp_gen[2])[4:])]\n",
    "    gen_hp_std = np.std(subj_hp_gen,0)/np.sqrt(len(subj_hp_gen))\n",
    "    \n",
    "    # Generalisation PFC\n",
    "    subj_pfc_gen = np.mean(subj_pfc_all,0)\n",
    "    subj_pfc_gen = [np.mean(np.diag(subj_pfc_gen[0])[4:]), np.mean(np.diag(subj_pfc_gen[1])[4:]),np.mean(np.diag(subj_pfc_gen[2])[4:]),\\\n",
    "                    np.mean(np.diag(subj_pfc_gen[3])[4:])]\n",
    "    gen_pfc_std = np.std(subj_pfc_gen)/np.sqrt(len(subj_pfc_gen))\n",
    "    generalisation = np.mean(subj_pfc_gen,0) - np.mean(subj_hp_gen,0) # difference between PFC and HP in generalisation to the same B\n",
    " \n",
    "    # Sequence HP\n",
    "    subj_hp_seq = np.mean(subj_hp_all,0)\n",
    "    subj_hp_seq = [np.mean([subj_hp_seq[0][4,1],subj_hp_seq[0][5,2],subj_hp_seq[0][6,3]]),\\\n",
    "                   np.mean([subj_hp_seq[1][4,1],subj_hp_seq[1][5,2],subj_hp_seq[1][6,3]]),\\\n",
    "                   np.mean([subj_hp_seq[2][4,1],subj_hp_seq[2][5,2],subj_hp_seq[2][6,3]])]  \n",
    "  \n",
    "    sequence_hp_std = np.std(subj_hp_seq,0)/np.sqrt(len(subj_hp_seq))\n",
    "    \n",
    "    # Sequence PFC\n",
    "    subj_pfc_seq = np.mean(subj_pfc_all,0) \n",
    "    subj_pfc_seq = [np.mean([subj_pfc_seq[0][4,1],subj_pfc_seq[0][5,2],subj_pfc_seq[0][6,3]]),\\\n",
    "                   np.mean([subj_pfc_seq[1][4,1],subj_pfc_seq[1][5,2],subj_pfc_seq[1][6,3]]),\\\n",
    "                   np.mean([subj_pfc_seq[2][4,1],subj_pfc_seq[2][5,2],subj_pfc_seq[2][6,3]]),\\\n",
    "                   np.mean([subj_pfc_seq[3][4,1],subj_pfc_seq[3][5,2],subj_pfc_seq[3][6,3]])]\n",
    "    \n",
    "    sequence_pfc_std = np.std(subj_pfc_seq,0)/np.sqrt(len(subj_pfc_seq))\n",
    "    seq_real = np.mean(subj_pfc_seq)- np.mean(subj_hp_seq)  # difference between PFC and HP in sequence decoding \n",
    "\n",
    "    ## PERMUTED DIFFERENCES\n",
    "    perm_all = np.asarray(perm_all); perm_all_2 = np.asarray(perm_all_2)\n",
    "\n",
    "    ### Init B task (task 2 --> 3; 3 --> 2)\n",
    "    perm_hp = np.mean([perm_all[5],perm_all_2[5]],0); perm_pfc = np.mean([perm_all[2],perm_all_2[2]],0)\n",
    "    perm_sp_hp_pfc = np.asarray(perm_hp- perm_pfc)\n",
    "    IB_perm = np.percentile(perm_sp_hp_pfc[:,0,4],95,0);\n",
    "    \n",
    "    # Significance for other decoding patterns averaged across all tasks \n",
    "    tasks_pfc = np.mean(np.mean([perm_all[:3], perm_all[:3]],0),0) # average across all task pairs\n",
    "    tasks_hp = np.mean(np.mean([perm_all[3:], perm_all[3:]],0),0) # average across all task pairs\n",
    "    perc_all = np.asarray(tasks_pfc - tasks_hp) # differences between PFC and HP \n",
    "    \n",
    "    # Sequence Significance\n",
    "    perc_all_seq = [np.percentile(perc_all[:,4,1],95,0), np.percentile(perc_all[:,5,2],95,0), np.percentile(perc_all[:,6,3],95,0)]\n",
    "    sequence_dif_sig = np.mean(perc_all_seq)\n",
    "   \n",
    "    # Generalisation Significance\n",
    "    perc_generalisation = [np.percentile(perc_all[:,4,4],95,0), np.percentile(perc_all[:,5,5],95,0), np.percentile(perc_all[:,6,5],95,0)]\n",
    "    generalisation_sig = np.mean(perc_generalisation)\n",
    "\n",
    "    labels = ['Correct','Position in Trial Sequence','Port']\n",
    "    sign_print = [generalisation > generalisation_sig, seq_real > sequence_dif_sig,IB_real > IB_perm]\n",
    "    for sg, sig in enumerate(sign_print):\n",
    "        if sig == True:\n",
    "            sign_text = 'p < 0.05'\n",
    "        else:\n",
    "            sign_text = 'NS'\n",
    "        print(labels[sg]+ ' ' + 'decoding' + ' ' + sign_text)\n",
    "\n",
    "    \n",
    "    # plot Correct, Position in Sequence and Port decoding patterns \n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "    cl = sns.color_palette(\"Set2\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x - width/2, [np.mean(subj_pfc_gen), np.mean(subj_pfc_seq),np.mean(subj_pfc_b)], width, label='PFC', color = cl[0], alpha = 0.5,\\\n",
    "                    yerr = [gen_pfc_std, sequence_pfc_std, std_pfc_b])\n",
    "    \n",
    "    ax.bar(x + width/2, [np.mean(subj_hp_gen), np.mean(subj_hp_seq), np.mean(subj_hp_b)], width, label='CA1', color = cl[1], alpha = 0.5,\\\n",
    "                    yerr = [gen_hp_std, sequence_hp_std, std_hp_b])\n",
    "\n",
    "    ax.set_xticks(x);  ax.set_xticklabels(labels); ax.legend()\n",
    "    \n",
    "    # plot subjects\n",
    "    hp_str = np.hstack([np.tile('Correct',4), np.tile('Position \\n in Trial Sequence',4),np.tile('Port',4), np.tile('Correct',3), np.tile('Position \\n in Trial Sequence',3), np.tile('Port',3),])\n",
    "    area = np.hstack([np.tile('PFC',12),np.tile('HP',9)]) \n",
    "    decode = np.hstack([subj_pfc_gen, subj_pfc_seq, subj_pfc_b,subj_hp_gen, subj_hp_seq, subj_hp_b])\n",
    "    data_ = {'Decoding': decode, 'Label': hp_str, 'Area':area}\n",
    "    df = pd.DataFrame(data = data_)\n",
    "    sns.swarmplot(x = \"Label\", y = \"Decoding (%)\", hue = 'Area', palette=\"Set2\", dodge = True, data = df)\n",
    "    sns.despine() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fig 3F, G\n",
    "plot(HP, PFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
